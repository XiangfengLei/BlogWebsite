---
title: Language Model
date: 2018-12-31 15:59:10
tags: BlogSpace
mathjax: ture
categories:
- Math
- Beautiful Math

---

一、机器智能
---
最早提出机器智能的设想的是计算机科学之父阿兰.图灵,提出验证机器是否智能的方法称为图灵测试法。如下图所示：
<!--more-->
二、统计语言模型
---
1.1 核心思想
---
一个句子是否合理，就是看它的可能性大小如何，至于可能性就用概率来衡量。
1.2 一个句子的二元模型
---
例如以下一个句子S，$w_i$为一个词：
$$S=w_1,w_2,...,w_n$$
则句子的概率为
$$P(S)=P(w_1,w_2,...,w_n)$$
根据条件概率得

$P(w_1,w_2,...,w_n) = P(w_1)*P(w_2|W_1)*P(w_3|w_1,W_2)*...*P(w_n|w_1,_w2,...,w_{n-1})\\$
由于$P(S)=P(w_1,w_2,...,w_n)$计算非常困难，德国数学家马尔可夫提出一种假设：
假设任意一个词$w_i$出现的概率只同它前面的词$w_{i-1}$有关。
由此可得二元模型：
$$P(S)=P(w_1)*P(w_2|w_1)*...*P(w_n|w_{n-1})$$
1.3 任意一个词的条件概率
---
根据条件概率定义：
$$P(w_i|w_{i-1})=\frac{P(w_{i-1},w_i)}{P(w_{i-1})}$$
现在估计联合概率$P(w_{i-1},w_i)$和边缘概率$P(w_{i-1})$变得比较简单了，只要在语料库中数一数$(w_{i-1},w_i)$这对词前后相邻出现了多少次，表示为#$(w_{i-1},w_i)$。同样数一数词$w_{i-1}$在语料库中出现的次数，表示为#$(w_{i-1})$。语料库的大小为#，即可得这些词或者二元组的相对频度：
$$f(w_{i-1},w_i)=\frac{\sharp(w_{i-1},w_i)}{\sharp}$$
$$f(w_{i-1})=\frac{\sharp(w_{i-1})}{\sharp}$$
根据大数定理，只要数据统计量足够，相对频度就等于概率：
$$P(w_{i-1},w_i)=\frac{\sharp(w_{i-1},w_i)}{\sharp}$$
$$P(w_{i-1})=\frac{\sharp(w_{i-1})}{\sharp}$$
由此可得
$$P(w_i|w_{i-1})=\frac{P(w_{i-1},w_i)}{P(w_{i-1})}=\frac{\sharp(w_{i-1},w_i)}{\sharp(w_{i-1})}$$
1.4 高阶语言模型
---
由二元模型扩展，假设句中的每个词$w_i$和前面的N-1个词有关，而与更前面的词无关，这样词$w_i$的条件概率为：
$$P(w_i|w_1,w_2,...,w_{i-1})=P(w_i|w_{i-N+1},w_{i-N+2},...,w_{i-1})$$
由于N如果比较大，计算的复杂度将以指数级增加，而且N大于3之后，效果的提升就不明显了，所以实际中应用最多的是N=3的三元模型，Google的系统使用的是四元模型。
其中|V|为一种语言词典的词汇量。N元模型算法的复杂度如下：
空间复杂度为$O(|V|^N)$
时间复杂度为$O(|V|^{N-1})$
1.5  模型的训练、零概率问题和平滑方法
---
在第1.3节中条件概率的计算，其中#$(w_{i-1},w_i)$和#$(w_{i-1})$由对语料库的统计中得到，但语料库未必存在词$(w_{i-1},w_i)$，或只出现一两次，此时计算的概率近乎等于零。这就是零概率问题。即使增加数据量，仍会遇到统计不足的问题。
这种用直接比值计算概率，大部分条件概率依然是零，这种模型我们称之为“不平滑”。
古德-图灵估计解决了这个问题,基本思想：
对于没有看见的事件，我们不能认为它发生的概率是零，因此从概率的总量中分配一个很小的比例给这些没看见的事件。此时已将所有看见的事件概率将小于1，至于小多少，要根据“越是不可信的统计折扣越多”的方法进行。


